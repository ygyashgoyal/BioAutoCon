{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c756b869",
   "metadata": {},
   "source": [
    "Connect GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9fdb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59709e41",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c62ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206c9fb",
   "metadata": {},
   "source": [
    "Model Path with Fine-Tuned Adaptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"/storage/home/sriramk/BTP_sriramk/pixtral/models--mistral-community--pixtral-12b/snapshots/c2756cbbb9422eba9f6c5c439a214b0392dfc998\"\n",
    "adapter_path = \"/storage/home/sriramk/BTP_sriramk/trained/pixtral-lora-finetuned-2\"\n",
    "test_image_path = \"/storage/home/sriramk/BTP_sriramk/1D_networks/rates/network_107.png\" # Replace with a test image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7271d5e",
   "metadata": {},
   "source": [
    "Load Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1525492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Base Model\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"  # Automatically splits across GPUs if needed, or puts on GPU 0\n",
    ")\n",
    "\n",
    "# Load and Merge the LoRA Adapter\n",
    "print(\"Loading LoRA adapter...\")\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "\n",
    "# Load Processor (Loaded from the fine-tuned path to ensure config matches)\n",
    "print(\"Loading processor...\")\n",
    "processor = AutoProcessor.from_pretrained(adapter_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a09d3b",
   "metadata": {},
   "source": [
    "Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e63710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image_path, prompt_text):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Apply template\n",
    "    text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "    # Prepare inputs and move to device\n",
    "    inputs = processor(text=text, images=image, return_tensors=\"pt\").to(model.device)\n",
    "    inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(model.dtype)\n",
    "    \n",
    "    # Generate\n",
    "    print(\"Generating response...\")\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=1000,\n",
    "            do_sample=False,        # Change to False for JSON/Code\n",
    "            # temperature=0.1,      # Only needed if do_sample=True\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode Output\n",
    "    output_text = processor.batch_decode(generated_ids[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "    \n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e7e24",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a785c88045e42afb2c8d89d0139f503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA adapter...\n",
      "Loading processor...\n",
      "Generating response...\n",
      "\n",
      "Result:\n",
      "------------------------------\n",
      "{\"nodes\": [{\"id\": \"A\"}], \"edges\": [{\"source\": \"A\", \"target\": \"φ\", \"type\": \"inhibition\", \"label\": \"k1\"}, {\"source\": \"A\", \"target\": \"A\", \"type\": \"inhibition\", \"label\": \"k2\"}, {\"source\": \"A\", \"target\": \"φ\", \"type\": \"inhibition\", \"label\": \"k3\"}, {\"source\": \"φ\", \"target\": \"A\", \"type\": \"activation\", \"label\": \"k4\"}], \"valid\": false}\n",
      "\n",
      "The diagram contains one node A with various connections:\n",
      "\n",
      "- There are inhibitory interactions (represented by red lines) from A to φ (labeled k1 and k3).\n",
      "- There's an inhibitory interaction from A back to itself (self-inhibition labeled k2).\n",
      "- There’s an activation interaction (represented by a black line) from φ to A (labeled k4).\n",
      "\n",
      "Given these observations:\n",
      "- The presence of self-inhibitory loop (k2) indicates that A inhibits its own production.\n",
      "- Inhibitory regulation from A to both φ (k1 and k3), combined with activation feedback from φ to A (k4), suggests potential instability in this regulatory mechanism.\n",
      "\n",
      "Considering typical biological networks where positive feedback loops can lead to non-physiological behaviors such as oscillations or instability, it appears that the depicted network might be invalid due to the combination of inhibition on activation creating a potentially unstable system.\n",
      "\n",
      "Thus, based upon standard biological principles, **the provided network seems invalid**.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. Run Test\n",
    "prompt = \"Analyze the diagram and extract nodes, edges, and generic symbolic ODEs. Also specify if the network is valid or not.\"\n",
    "response = run_inference(test_image_path, prompt)\n",
    "\n",
    "print(\"\\nResult:\")\n",
    "print(\"-\" * 30)\n",
    "print(response)\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base-GPU)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
